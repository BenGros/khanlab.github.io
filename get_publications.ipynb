{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74557173",
   "metadata": {
    "papermill": {
     "duration": 0.017211,
     "end_time": "2022-01-01T05:13:16.233140",
     "exception": false,
     "start_time": "2022-01-01T05:13:16.215929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "_Adapted from notebook used by [nbclab.github.io](https://nbclab.github.io)._\n",
    "\n",
    "# Retrieve new publications from PubMed \n",
    "\n",
    "This notebook is used to search for and retrieve latest publications by Dr. Khan using BioPython's PubMed search tool. A publication-specific MarkDown file is generated for each unique paper, with many elements automatically set up. As noted in the original notebook, you generally should check that the link to the markdown file exists. Unfortunately, preprints cannot be found via this method (though they can be added manually). This notebook cannot find new preprints. The process is automated and runs monthly using Github actions.\n",
    "\n",
    "## Steps (via Github or manual)\n",
    "\n",
    "1. Run this notebook.\n",
    "2. If any new papers were grabbed, check the following:\n",
    "    1. The paper has either of the lab PIs as an author. Ensure that it isn't by *another* AR Khan.\n",
    "    2. The paper is not a duplicate of a preprint or another version of the paper. If so, merge the two versions.\n",
    "3. Save the changes to the notebook.\n",
    "4. Push changes to the notebook and affected files to GitHub.\n",
    "5. Open a pull request to khanlab/khanlab.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22f3858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T05:13:16.274361Z",
     "iopub.status.busy": "2022-01-01T05:13:16.273872Z",
     "iopub.status.idle": "2022-01-01T05:13:16.556013Z",
     "shell.execute_reply": "2022-01-01T05:13:16.555426Z"
    },
    "papermill": {
     "duration": 0.307226,
     "end_time": "2022-01-01T05:13:16.556161",
     "exception": false,
     "start_time": "2022-01-01T05:13:16.248935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "from Bio import Entrez, Medline\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9095c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T05:13:16.593069Z",
     "iopub.status.busy": "2022-01-01T05:13:16.592505Z",
     "iopub.status.idle": "2022-01-01T05:13:16.596997Z",
     "shell.execute_reply": "2022-01-01T05:13:16.597373Z"
    },
    "papermill": {
     "duration": 0.0257,
     "end_time": "2022-01-01T05:13:16.597501",
     "exception": false,
     "start_time": "2022-01-01T05:13:16.571801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First count number of articles from previous grab\n",
    "try:\n",
    "    df = pd.read_csv(\"_data/publications/publications.csv\")\n",
    "    old_count = len(df)\n",
    "except:\n",
    "    old_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700613de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T05:13:16.631111Z",
     "iopub.status.busy": "2022-01-01T05:13:16.630646Z",
     "iopub.status.idle": "2022-01-01T05:13:16.632578Z",
     "shell.execute_reply": "2022-01-01T05:13:16.632925Z"
    },
    "papermill": {
     "duration": 0.020277,
     "end_time": "2022-01-01T05:13:16.633047",
     "exception": false,
     "start_time": "2022-01-01T05:13:16.612770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only grab papers from after the lab PI came to UWO\n",
    "search_criteria = ['''\"Khan AR\"[AUTH] AND (\"2015/01/01\"[PDAT] : \"3000/12/31\"[PDAT]) AND\n",
    "                    (\"Western University\"[AFFL] OR \"University of Western Ontario\"[AFFL] OR\n",
    "                     \"Brain and Mind Institute\"[AFFL] OR \"Robarts Research Institute\"[AFFL])''']\n",
    "\n",
    "# Email required to search\n",
    "Entrez.email = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad1de07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T05:13:16.663206Z",
     "iopub.status.busy": "2022-01-01T05:13:16.662716Z",
     "iopub.status.idle": "2022-01-01T05:13:18.744374Z",
     "shell.execute_reply": "2022-01-01T05:13:18.744753Z"
    },
    "papermill": {
     "duration": 2.098033,
     "end_time": "2022-01-01T05:13:18.744896",
     "exception": false,
     "start_time": "2022-01-01T05:13:16.646863",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of publications containing \"Khan AR\"[AUTH] AND (\"2015/01/01\"[PDAT] : \"3000/12/31\"[PDAT]) AND\n",
      "                    (\"Western University\"[AFFL] OR \"University of Western Ontario\"[AFFL] OR\n",
      "                     \"Brain and Mind Institute\"[AFFL] OR \"Robarts Research Institute\"[AFFL]): 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving identified publications to csv...\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# Publications to skip (possibly due to another user with same initial)\n",
    "skip_pmids = [32971934, 29641820, 29634829]\n",
    "skip_pmids = [str(pmid) for pmid in skip_pmids]\n",
    "\n",
    "for TERM in search_criteria:\n",
    "    search = Entrez.esearch(db=\"pubmed\", retmax=\"2\", term=TERM)\n",
    "    result = Entrez.read(search)\n",
    "    print(f\"Total number of publications containing {TERM}: {result['Count']}\")\n",
    "    \n",
    "    search_all = Entrez.esearch(db=\"pubmed\", term=TERM, retmax=result[\"Count\"])\n",
    "    result_all = Entrez.read(search_all)\n",
    "    ids_all = result_all['IdList']\n",
    "    pubs_all = Entrez.efetch(db=\"pubmed\", id=ids_all, rettype='medline', retmode='text')\n",
    "    records = Medline.parse(pubs_all)\n",
    "    \n",
    "    acceptable_formats = [\"journal article\", \"comparative study\", \"editorial\"]\n",
    "    \n",
    "    for record in records:\n",
    "        if any([type_.lower() in acceptable_formats for type_ in record.get('PT')]):\n",
    "            pmid = record.get(\"PMID\")\n",
    "            pmcid = record.get(\"PMC\", \"\")\n",
    "            \n",
    "            doi = [aid for aid in record.get(\"AID\", []) if aid.endswith(\" [doi]\")]\n",
    "            if doi:\n",
    "                doi = doi[0].replace(\" [doi]\", \"\")\n",
    "            else:\n",
    "                doi = \"\"\n",
    "            \n",
    "            title = record.get(\"TI\").rstrip(\".\")\n",
    "            authors = record.get(\"AU\")\n",
    "            \n",
    "            # Allow for cell to continue even if error with parsing date\n",
    "            try:\n",
    "                pub_date = parser.parse(record.get(\"DP\"))\n",
    "            except:\n",
    "                None\n",
    "            journal = record.get('TA')\n",
    "            volume = record.get('VI', '')\n",
    "            issue = record.get('IP', '')\n",
    "            pages = record.get('PG', '')\n",
    "            \n",
    "            row = [pmid, pmcid, doi, title, authors, pub_date.year, pub_date.month,\n",
    "                   pub_date.day, journal, volume, issue, pages]\n",
    "            rows += [row]\n",
    "            \n",
    "# Save all relevant info from articles to a csv.\n",
    "print(\"Saving identified publications to csv...\")\n",
    "df = pd.DataFrame(columns=['pmid', 'pmcid', 'doi', 'title', 'authors',\n",
    "                           'year', 'month', 'day',\n",
    "                           'journal', 'volume', 'issue', 'pages'],\n",
    "                  data=rows)\n",
    "df = df[~df[\"pmid\"].isin(skip_pmids)]\n",
    "df = df.sort_values(by=['year', 'month', 'day'], ascending=False)\n",
    "df.to_csv('_data/publications/publications.csv', index=False)\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70df731e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T05:13:18.782538Z",
     "iopub.status.busy": "2022-01-01T05:13:18.782065Z",
     "iopub.status.idle": "2022-01-01T05:13:18.784633Z",
     "shell.execute_reply": "2022-01-01T05:13:18.785050Z"
    },
    "papermill": {
     "duration": 0.024651,
     "end_time": "2022-01-01T05:13:18.785202",
     "exception": false,
     "start_time": "2022-01-01T05:13:18.760551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 total articles found.\n",
      "0 new articles found.\n"
     ]
    }
   ],
   "source": [
    "# Add papers we already have pages for.\n",
    "if len(skip_pmids) > 0:\n",
    "    for pmid in skip_pmids:\n",
    "        df = df[df['pmid'] != pmid]\n",
    "        \n",
    "    \n",
    "print(f\"{len(df)} total articles found.\")\n",
    "print(f\"{len(df) - old_count} new articles found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e9b21",
   "metadata": {
    "papermill": {
     "duration": 0.01622,
     "end_time": "2022-01-01T05:13:18.817611",
     "exception": false,
     "start_time": "2022-01-01T05:13:18.801391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "14e56145dce856ace041bb8c7d4e36292feda7ae3b6a8932c4dc4ea60aa62137"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.khanlab_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.645604,
   "end_time": "2022-01-01T05:13:19.041125",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/runner/work/khanlab.github.io/khanlab.github.io/get_publications.ipynb",
   "output_path": "/home/runner/work/khanlab.github.io/khanlab.github.io/get_publications.ipynb",
   "parameters": {},
   "start_time": "2022-01-01T05:13:14.395521",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}